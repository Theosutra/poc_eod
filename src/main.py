#!/usr/bin/env python3
"""
Pipeline RAG principal pour EODEN
Orchestration compl√®te : Drive ‚Üí Chunking ‚Üí Embeddings ‚Üí Vector Store
"""

import os
import sys
import logging
from pathlib import Path
from typing import Dict, List, Any
import yaml
from dotenv import load_dotenv
from tqdm import tqdm

# Imports locaux
from drive_connector import DriveConnector
from simplified_embedding_manager import SimplifiedEmbeddingManager, SimplifiedChunk
from vector_store import VectorManager, VectorDocument

# Configuration du logging
import os
os.makedirs("logs", exist_ok=True)  # Cr√©er le dossier logs s'il n'existe pas

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/poc.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class RAGPipeline:
    """Pipeline principal RAG pour EODEN"""
    
    def __init__(self, config_path: str = "config/settings.yaml"):
        # Charger la configuration
        load_dotenv()
        self.config = self._load_config(config_path)
        
        # Initialiser les composants
        self.drive_connector = None
        self.embedding_manager = None
        self.vector_manager = None
        
        self._setup_directories()
        self._init_components()
    
    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """Charger la configuration YAML"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            
            # Substituer les variables d'environnement
            config = self._substitute_env_vars(config)
            logger.info(f"Configuration charg√©e: {config_path}")
            return config
            
        except Exception as e:
            logger.error(f"Erreur chargement config: {e}")
            sys.exit(1)
    
    def _substitute_env_vars(self, obj):
        """Substituer les variables d'environnement dans la config"""
        if isinstance(obj, dict):
            return {k: self._substitute_env_vars(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [self._substitute_env_vars(item) for item in obj]
        elif isinstance(obj, str) and obj.startswith('${') and obj.endswith('}'):
            env_var = obj[2:-1]
            return os.getenv(env_var, obj)
        else:
            return obj
    
    def _setup_directories(self):
        """Cr√©er les r√©pertoires n√©cessaires"""
        directories = [
            "data/cache",
            "data/embeddings", 
            "data/output",
            "logs",
            "config"
        ]
        
        for dir_path in directories:
            Path(dir_path).mkdir(parents=True, exist_ok=True)
    
    def _init_components(self):
        """Initialiser les composants du pipeline"""
        try:
            # Google Drive Connector
            logger.info("üîó Initialisation Google Drive...")
            self.drive_connector = DriveConnector(
                credentials_path=self.config['google_drive']['credentials_file'],
                cache_dir=self.config['google_drive']['cache_directory']
            )
            
            # Simplified Embedding Manager
            logger.info("üß† Initialisation Simplified Embedding Manager...")
            gemini_api_key = self.config['apis']['gemini_api_key']
            if not gemini_api_key:
                raise ValueError("GEMINI_API_KEY manquant dans .env")
            
            self.embedding_manager = SimplifiedEmbeddingManager(
                api_key=gemini_api_key,
                cache_dir=self.config['embeddings']['cache_directory']
            )
            
            # Vector Store Manager
            logger.info("üì¶ Initialisation Vector Store...")
            self.vector_manager = VectorManager(config_path="config/settings.yaml")
            
            logger.info("‚úÖ Tous les composants initialis√©s")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur initialisation: {e}")
            sys.exit(1)
    
    def discover_documents(self) -> List[Dict[str, Any]]:
        """D√©couvrir les documents dans Google Drive"""
        logger.info("üîç D√©couverte des documents Google Drive...")
        
        all_files = []
        
        # Parcourir les dossiers configur√©s
        for folder_config in self.config['google_drive']['source_folders']:
            folder_name = folder_config['name']
            recursive = folder_config.get('recursive', True)
            
            logger.info(f"üìÅ Exploration du dossier: {folder_name}")
            
            # Trouver le dossier
            folder_id = self.drive_connector.get_folder_by_name(folder_name)
            if not folder_id:
                logger.warning(f"‚ö†Ô∏è Dossier non trouv√©: {folder_name}")
                continue
            
            # Lister les fichiers
            files = self.drive_connector.list_files(folder_id, recursive=recursive)
            all_files.extend(files)
            logger.info(f"‚úÖ {len(files)} fichiers trouv√©s dans {folder_name}")
        
        # Filtrer par extensions support√©es
        supported_exts = self.config['google_drive']['supported_extensions']
        filtered_files = []
        
        for file_info in all_files:
            file_name = file_info['name']
            if any(file_name.lower().endswith(ext.lower()) for ext in supported_exts):
                filtered_files.append(file_info)
        
        logger.info(f"üéØ {len(filtered_files)} fichiers support√©s d√©couverts")
        return filtered_files
    
    def download_documents(self, files_info: List[Dict[str, Any]]) -> Dict[str, str]:
        """T√©l√©charger et extraire le contenu des documents"""
        logger.info("‚¨áÔ∏è T√©l√©chargement des documents...")
        
        downloaded_contents = {}
        
        with tqdm(total=len(files_info), desc="T√©l√©chargement") as pbar:
            for file_info in files_info:
                try:
                    # T√©l√©charger le fichier
                    cache_path = self.drive_connector.download_file(
                        file_info['id'],
                        file_info['name'],
                        file_info['mimeType']
                    )
                    
                    if cache_path:
                        # Extraire le contenu
                        content = self._extract_content(cache_path)
                        if content:
                            downloaded_contents[str(cache_path)] = content
                            logger.debug(f"‚úÖ Contenu extrait: {file_info['name']}")
                        else:
                            logger.warning(f"‚ö†Ô∏è Extraction √©chou√©e: {file_info['name']}")
                    
                except Exception as e:
                    logger.error(f"‚ùå Erreur t√©l√©chargement {file_info['name']}: {e}")
                
                pbar.update(1)
        
        logger.info(f"‚úÖ {len(downloaded_contents)} documents t√©l√©charg√©s et extraits")
        return downloaded_contents
    
    def _extract_content(self, file_path: Path) -> str:
        """Extraire le contenu textuel d'un fichier"""
        try:
            file_ext = file_path.suffix.lower()
            
            if file_ext == '.pdf':
                return self._extract_pdf_content(file_path)
            elif file_ext == '.docx':
                return self._extract_docx_content(file_path)
            elif file_ext == '.pptx':
                return self._extract_pptx_content(file_path)
            elif file_ext == '.xlsx':
                return self._extract_xlsx_content(file_path)
            else:
                logger.warning(f"Type de fichier non support√©: {file_ext}")
                return ""
                
        except Exception as e:
            logger.error(f"Erreur extraction {file_path}: {e}")
            return ""
    
    def _extract_pdf_content(self, file_path: Path) -> str:
        """Extraire le contenu d'un PDF avec OCR des images"""
        import pymupdf  # fitz
        
        text = ""
        doc = pymupdf.open(str(file_path))
        
        for page_num in range(doc.page_count):
            page = doc[page_num]
            text += f"\n--- Page {page_num + 1} ---\n"
            
            # Extraire le texte normal
            page_text = page.get_text()
            text += page_text
            
            # Si peu de texte, essayer l'OCR sur les images
            if len(page_text.strip()) < 100:
                try:
                    ocr_text = self._extract_images_with_ocr(page)
                    if ocr_text:
                        text += f"\n[OCR] {ocr_text}"
                        logger.info(f"OCR appliqu√© sur page {page_num + 1}")
                except Exception as e:
                    logger.warning(f"Erreur OCR page {page_num + 1}: {e}")
        
        doc.close()
        return text.strip()
    
    def _extract_docx_content(self, file_path: Path) -> str:
        """Extraire le contenu d'un Word"""
        from docx import Document
        
        doc = Document(str(file_path))
        text = ""
        
        for paragraph in doc.paragraphs:
            text += paragraph.text + "\n"
        
        # Extraire les tableaux
        for table in doc.tables:
            for row in table.rows:
                row_text = " | ".join(cell.text for cell in row.cells)
                text += row_text + "\n"
        
        return text.strip()
    
    def _extract_pptx_content(self, file_path: Path) -> str:
        """Extraire le contenu d'un PowerPoint avec OCR des images"""
        from pptx import Presentation
        
        prs = Presentation(str(file_path))
        text = ""
        
        for slide_num, slide in enumerate(prs.slides, 1):
            text += f"\n--- Slide {slide_num} ---\n"
            
            slide_text = ""
            for shape in slide.shapes:
                if hasattr(shape, "text"):
                    slide_text += shape.text + "\n"
            
            text += slide_text
            
            # Si peu de texte sur la slide, essayer l'OCR sur les images
            if len(slide_text.strip()) < 50:
                try:
                    ocr_text = self._extract_slide_images_with_ocr(slide)
                    if ocr_text:
                        text += f"\n[OCR] {ocr_text}"
                        logger.info(f"OCR appliqu√© sur slide {slide_num}")
                except Exception as e:
                    logger.warning(f"Erreur OCR slide {slide_num}: {e}")
        
        return text.strip()
    
    def _extract_xlsx_content(self, file_path: Path) -> str:
        """Extraire le contenu d'un Excel"""
        import pandas as pd
        
        text = ""
        
        try:
            # Lire toutes les feuilles
            excel_file = pd.ExcelFile(str(file_path))
            
            for sheet_name in excel_file.sheet_names:
                df = pd.read_excel(str(file_path), sheet_name=sheet_name)
                
                text += f"\n--- Feuille: {sheet_name} ---\n"
                
                # Convertir en texte structur√©
                for index, row in df.iterrows():
                    row_text = " | ".join(str(value) for value in row.values if pd.notna(value))
                    if row_text.strip():
                        text += row_text + "\n"
        
        except Exception as e:
            logger.warning(f"Erreur lecture Excel {file_path}: {e}")
        
        return text.strip()
    
    def _extract_images_with_ocr(self, page) -> str:
        """Extraire le texte des images d'une page PDF avec OCR"""
        try:
            # M√©thode 1: Gemini Vision (intelligent, m√™me API)
            return self._ocr_with_gemini_vision(page)
        except Exception as e:
            logger.warning(f"Gemini Vision OCR failed: {e}")
            try:
                # M√©thode 2: Tesseract (fallback gratuit)
                return self._ocr_with_tesseract(page)
            except Exception as e2:
                logger.warning(f"Tesseract OCR failed: {e2}")
                try:
                    # M√©thode 3: Google Vision API (fallback pr√©cis)
                    return self._ocr_with_google_vision(page)
                except Exception as e3:
                    logger.warning(f"Google Vision OCR failed: {e3}")
                    return ""
    
    def _ocr_with_gemini_vision(self, page) -> str:
        """OCR avec Gemini Vision (intelligent et contextuel)"""
        try:
            import google.generativeai as genai
            import base64
            import io
            
            # Extraire les images de la page
            image_list = page.get_images(full=True)
            ocr_texts = []
            
            for img_index, img in enumerate(image_list):
                try:
                    # R√©cup√©rer l'image
                    xref = img[0]
                    base_image = page.parent.extract_image(xref)
                    image_bytes = base_image["image"]
                    
                    # Encoder en base64 pour Gemini
                    image_b64 = base64.b64encode(image_bytes).decode('utf-8')
                    
                    # Prompt optimis√© pour Gemini 2.0 Flash
                    prompt = """
                    Vous √™tes un expert en analyse de documents d'investissement. Analysez cette image avec une pr√©cision maximale.
                    
                    MISSIONS:
                    1. OCR complet: Extraire TOUT le texte visible avec une pr√©cision parfaite
                    2. Analyse financi√®re: Identifier toutes les m√©triques, ratios, √©volutions
                    3. Structuration intelligente: Organiser les donn√©es pour faciliter l'analyse
                    4. Insights business: D√©gager les tendances et signaux cl√©s
                    
                    FORMAT DE SORTIE:
                    
                    TEXTE EXTRAIT:
                    [Transcription exacte de tout le texte visible]
                    
                    M√âTRIQUES FINANCI√àRES:
                    [Lister tous les chiffres avec unit√©s: CA, EBITDA, croissance, ratios, etc.]
                    
                    DONN√âES TEMPORELLES:
                    [√âvolutions, comparaisons annuelles, tendances identifi√©es]
                    
                    INSIGHTS CL√âS:
                    [Points saillants pour un investisseur: performance, risques, opportunit√©s]
                    
                    TYPE DE CONTENU:
                    [Graphique/Tableau/Diagramme/Sch√©ma + description technique]
                    
                    Soyez exhaustif et pr√©cis. Gemini 2.5 Excellence attendue.
                    """
                    
                    # Cr√©er le mod√®le Gemini Vision 2.5
                    model = genai.GenerativeModel('gemini-2.5-flash')
                    
                    # Analyser l'image
                    response = model.generate_content([
                        prompt,
                        {
                            "mime_type": f"image/{base_image.get('ext', 'png')}",
                            "data": image_b64
                        }
                    ])
                    
                    if response.text and response.text.strip():
                        analyzed_content = response.text.strip()
                        ocr_texts.append(f"[Image {img_index + 1} - Gemini Analysis]\n{analyzed_content}")
                        logger.info(f"Gemini Vision OCR r√©ussi pour image {img_index + 1}")
                        
                except Exception as e:
                    logger.warning(f"Erreur Gemini Vision image {img_index}: {e}")
                    continue
            
            return "\n\n".join(ocr_texts)
            
        except Exception as e:
            logger.warning(f"Gemini Vision OCR non disponible: {e}")
            raise e
    
    def _ocr_with_tesseract(self, page) -> str:
        """OCR avec Tesseract (gratuit)"""
        try:
            import pytesseract
            from PIL import Image
            import io
            
            # Extraire les images de la page
            image_list = page.get_images(full=True)
            ocr_texts = []
            
            for img_index, img in enumerate(image_list):
                try:
                    # R√©cup√©rer l'image
                    xref = img[0]
                    base_image = page.parent.extract_image(xref)
                    image_bytes = base_image["image"]
                    
                    # Convertir en PIL Image
                    image = Image.open(io.BytesIO(image_bytes))
                    
                    # OCR avec Tesseract
                    text = pytesseract.image_to_string(image, lang='fra+eng')
                    
                    if text.strip():
                        ocr_texts.append(f"[Image {img_index + 1}] {text.strip()}")
                        
                except Exception as e:
                    logger.warning(f"Erreur OCR image {img_index}: {e}")
                    continue
            
            return "\n".join(ocr_texts)
            
        except ImportError:
            logger.warning("pytesseract non install√©. Installer avec: pip install pytesseract")
            return ""
    
    def _ocr_with_google_vision(self, page) -> str:
        """OCR avec Google Vision API (plus pr√©cis mais payant)"""
        try:
            from google.cloud import vision
            import io
            
            client = vision.ImageAnnotatorClient()
            image_list = page.get_images(full=True)
            ocr_texts = []
            
            for img_index, img in enumerate(image_list):
                try:
                    # R√©cup√©rer l'image
                    xref = img[0]
                    base_image = page.parent.extract_image(xref)
                    image_bytes = base_image["image"]
                    
                    # Analyser avec Google Vision
                    image = vision.Image(content=image_bytes)
                    response = client.text_detection(image=image)
                    
                    if response.text_annotations:
                        text = response.text_annotations[0].description
                        ocr_texts.append(f"[Image {img_index + 1}] {text.strip()}")
                        
                except Exception as e:
                    logger.warning(f"Erreur Google Vision image {img_index}: {e}")
                    continue
            
            return "\n".join(ocr_texts)
            
        except ImportError:
            logger.warning("Google Cloud Vision non install√©. Installer avec: pip install google-cloud-vision")
            return ""
    
    def _extract_slide_images_with_ocr(self, slide) -> str:
        """Extraire le texte des images d'une slide PowerPoint avec Gemini Vision"""
        try:
            import google.generativeai as genai
            import base64
            import io
            from PIL import Image
            
            ocr_texts = []
            
            # Parcourir les formes de la slide
            for shape_index, shape in enumerate(slide.shapes):
                # V√©rifier si c'est une image
                if hasattr(shape, 'image'):
                    try:
                        # M√©thode 1: Gemini Vision
                        try:
                            # Extraire l'image
                            image_bytes = shape.image.blob
                            image_b64 = base64.b64encode(image_bytes).decode('utf-8')
                            
                            # Prompt optimis√© pour slides avec Gemini 2.0
                            prompt = """
                            Analysez cette image de slide de pr√©sentation business avec la puissance de Gemini 2.0.
                            
                            EXTRACTION COMPL√àTE:
                            1. OCR exhaustif de tout le texte (titres, sous-titres, l√©gendes, annotations)
                            2. Donn√©es quantitatives: chiffres, pourcentages, ratios, dates
                            3. √âl√©ments visuels: graphiques, sch√©mas, fl√®ches, codes couleur
                            4. Message strat√©gique: objectif de la slide pour l'audience
                            
                            STRUCTURE DE R√âPONSE:
                            
                            CONTENU TEXTUEL:
                            [Transcription compl√®te et structur√©e]
                            
                            DONN√âES BUSINESS:
                            [M√©triques, KPIs, projections, comparatifs]
                            
                            √âL√âMENTS VISUELS:
                            [Description des graphiques, sch√©mas, diagrammes]
                            
                            MESSAGE STRAT√âGIQUE:
                            [Objectif de communication, points cl√©s pour investisseurs]
                            
                            CONTEXTE SLIDE:
                            [Position probable dans la pr√©sentation, audience cible]
                            
                            Exploitez pleinement Gemini 2.5 pour une analyse approfondie.
                            """
                            
                            model = genai.GenerativeModel('gemini-2.5-flash')
                            response = model.generate_content([
                                prompt,
                                {
                                    "mime_type": "image/png",
                                    "data": image_b64
                                }
                            ])
                            
                            if response.text and response.text.strip():
                                analyzed_content = response.text.strip()
                                ocr_texts.append(f"[Slide Image {shape_index + 1} - Gemini]\n{analyzed_content}")
                                logger.info(f"Gemini Vision OCR r√©ussi pour slide image {shape_index + 1}")
                                continue
                                
                        except Exception as e:
                            logger.warning(f"Gemini Vision slide failed: {e}")
                        
                        # M√©thode 2: Fallback Tesseract
                        try:
                            import pytesseract
                            image = Image.open(io.BytesIO(image_bytes))
                            text = pytesseract.image_to_string(image, lang='fra+eng')
                            
                            if text.strip():
                                ocr_texts.append(f"[Slide Image {shape_index + 1}] {text.strip()}")
                                
                        except Exception as e2:
                            logger.warning(f"Tesseract slide OCR failed: {e2}")
                            continue
                            
                    except Exception as e:
                        logger.warning(f"Erreur OCR image slide {shape_index}: {e}")
                        continue
            
            return "\n\n".join(ocr_texts)
            
        except Exception as e:
            logger.warning(f"Erreur g√©n√©rale OCR slides: {e}")
            return ""
    
    def _should_apply_ocr(self, content: str, file_path: str) -> bool:
        """D√©terminer si l'OCR doit √™tre appliqu√©"""
        # Configuration OCR
        ocr_config = self.config.get('ocr', {})
        
        # OCR d√©sactiv√© globalement
        if not ocr_config.get('enabled', False):
            return False
        
        # Types de fichiers support√©s
        supported_types = ocr_config.get('supported_types', ['.pdf', '.pptx'])
        file_ext = os.path.splitext(file_path.lower())[1]
        
        if file_ext not in supported_types:
            return False
        
        # Seuil de texte minimum pour d√©clencher OCR
        min_text_threshold = ocr_config.get('min_text_threshold', 100)
        
        return len(content.strip()) < min_text_threshold
    
    def process_embeddings(self, file_contents: Dict[str, str]) -> List[SimplifiedChunk]:
        """Traiter les documents : chunking + embeddings"""
        logger.info("üß† Traitement des embeddings...")
        
        # Traitement en batch
        processed_chunks = self.embedding_manager.batch_process_documents(file_contents)
        
        logger.info(f"‚úÖ {len(processed_chunks)} chunks trait√©s")
        
        # Afficher les m√©triques de performance
        self.embedding_manager.print_metrics()
        
        return processed_chunks
    
    def store_in_vector_db(self, processed_chunks: List[SimplifiedChunk]) -> bool:
        """Stocker les chunks dans la base vectorielle"""
        logger.info("üì¶ Stockage dans la base vectorielle...")
        
        # Convertir en VectorDocument
        vector_docs = []
        for chunk in processed_chunks:
            vector_doc = VectorDocument(
                id=chunk.id,
                content=chunk.metadata.contenu_chunk,  # Utiliser le contenu original
                embedding=chunk.embedding,
                metadata={
                    "source_file": chunk.metadata.nom_document,
                    "document_type": "simplified",  # Type simplifi√©
                    "section_title": chunk.enriched_content.theme_principal,
                    "business_context": chunk.enriched_content.commentaire_guidage,
                    "themes": [chunk.enriched_content.theme_principal],
                    "confidence_score": 1.0,  # Score par d√©faut
                    "chunk_index": chunk.metadata.chunk_index,
                    "token_count": chunk.metadata.taille_chunk,
                    "file_hash": chunk.id.split("_")[0],  # Extraire du ID
                    "created_at": chunk.metadata.date_creation,
                    "dossier_racine": chunk.metadata.dossier_racine,
                    "contenu_enrichi": chunk.enriched_content.contenu_enrichi
                }
            )
            vector_docs.append(vector_doc)
        
        # Stocker en batch
        batch_size = self.config['embeddings']['batch_size']
        total_stored = 0
        
        with tqdm(total=len(vector_docs), desc="Stockage vectoriel") as pbar:
            for i in range(0, len(vector_docs), batch_size):
                batch = vector_docs[i:i + batch_size]
                
                if self.vector_manager.add_documents(batch):
                    total_stored += len(batch)
                    logger.debug(f"Batch {i//batch_size + 1} stock√©: {len(batch)} documents")
                else:
                    logger.error(f"Erreur stockage batch {i//batch_size + 1}")
                
                pbar.update(len(batch))
        
        logger.info(f"‚úÖ {total_stored} documents stock√©s dans la base vectorielle")
        return total_stored == len(vector_docs)
    
    def test_search(self, query: str = "analyse financi√®re") -> List[VectorDocument]:
        """Tester la recherche vectorielle"""
        logger.info(f"üîç Test de recherche: '{query}'")
        
        # G√©n√©rer l'embedding de la requ√™te
        query_embedding = self.embedding_manager.get_embedding(query)
        
        # Rechercher
        results = self.vector_manager.search_similar(
            query_embedding=query_embedding,
            top_k=5
        )
        
        logger.info(f"‚úÖ {len(results)} r√©sultats trouv√©s")
        
        for i, result in enumerate(results, 1):
            logger.info(f"R√©sultat {i}:")
            logger.info(f"  Score: {result.score:.3f}")
            logger.info(f"  Source: {result.metadata.get('source_file', 'Unknown')}")
            logger.info(f"  Section: {result.metadata.get('section_title', 'Unknown')}")
            logger.info(f"  Contenu: {result.content[:150]}...")
            logger.info("-" * 50)
        
        return results
    
    def run_full_pipeline(self) -> bool:
        """Ex√©cuter le pipeline complet"""
        logger.info("üöÄ D√©marrage du pipeline RAG complet")
        
        try:
            # 1. D√©couvrir les documents
            files_info = self.discover_documents()
            if not files_info:
                logger.error("‚ùå Aucun document trouv√©")
                return False
            
            # 2. T√©l√©charger et extraire le contenu
            file_contents = self.download_documents(files_info)
            if not file_contents:
                logger.error("‚ùå Aucun contenu extrait")
                return False
            
            # 3. Traitement des embeddings
            processed_chunks = self.process_embeddings(file_contents)
            if not processed_chunks:
                logger.error("‚ùå Aucun chunk trait√©")
                return False
            
            # 4. Stockage vectoriel
            success = self.store_in_vector_db(processed_chunks)
            if not success:
                logger.error("‚ùå Erreur stockage vectoriel")
                return False
            
            # 5. Test de recherche
            self.test_search("strat√©gie entreprise")
            self.test_search("chiffres financiers")
            
            logger.info("üéâ Pipeline RAG termin√© avec succ√®s!")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur pipeline: {e}")
            return False
    
    def get_stats(self) -> Dict[str, Any]:
        """Obtenir les statistiques du pipeline"""
        metrics = self.embedding_manager.get_metrics()
        return {
            "cache_files": len(list(Path(self.config['google_drive']['cache_directory']).glob("*"))),
            "embedding_cache_size": metrics["cache_sizes"]["embedding_cache"],
            "enrichment_cache_size": metrics["cache_sizes"]["enrichment_cache"],
            "embeddings_generated": metrics["embeddings_generated"],
            "enrichments_generated": metrics["enrichments_generated"],
            "vector_store_type": self.config['vector_store']['type'],
            "index_name": self.config['vector_store']['index_name']
        }

def main():
    """Point d'entr√©e principal"""
    print("üöÄ Pipeline RAG EODEN - D√©marrage")
    
    # V√©rifier les pr√©requis
    required_files = [
        "config/settings.yaml",
        "config/credentials.json",
        ".env"
    ]
    
    for file_path in required_files:
        if not Path(file_path).exists():
            print(f"‚ùå Fichier manquant: {file_path}")
            print("Assurez-vous d'avoir configur√© tous les pr√©requis")
            return
    
    # Cr√©er et ex√©cuter le pipeline
    try:
        pipeline = RAGPipeline()
        
        # Afficher les statistiques initiales
        stats = pipeline.get_stats()
        print(f"üìä Statistiques initiales: {stats}")
        
        # Ex√©cuter le pipeline
        success = pipeline.run_full_pipeline()
        
        if success:
            # Afficher les statistiques finales
            final_stats = pipeline.get_stats()
            print(f"üìä Statistiques finales: {final_stats}")
            print("‚úÖ Pipeline termin√© avec succ√®s!")
        else:
            print("‚ùå Pipeline √©chou√©")
            
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è Pipeline interrompu par l'utilisateur")
    except Exception as e:
        print(f"‚ùå Erreur critique: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()