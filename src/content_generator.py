"""
GÃ©nÃ©rateur de contenu pour les notes d'investissement
Utilise la base vectorielle pour crÃ©er du contenu intelligent
"""

import os
import logging
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
import google.generativeai as genai
from dotenv import load_dotenv

# Imports locaux
from vector_store import VectorManager
from embedding_manager import EmbeddingManager

logger = logging.getLogger(__name__)

@dataclass
class GeneratedSection:
    """Section gÃ©nÃ©rÃ©e avec mÃ©tadonnÃ©es"""
    title: str
    content: str
    confidence_score: float
    sources_used: List[str]
    chunk_count: int

class ContentGenerator:
    """GÃ©nÃ©rateur de contenu intelligent"""
    
    def __init__(self, config_path: str = "config/settings.yaml"):
        load_dotenv()
        
        # Initialiser les composants
        self.embedding_manager = EmbeddingManager(
            api_key=os.getenv("GEMINI_API_KEY")
        )
        self.vector_manager = VectorManager(config_path)
        
        # ModÃ¨le de gÃ©nÃ©ration
        genai.configure(api_key=os.getenv("GEMINI_API_KEY"))
        self.generation_model = genai.GenerativeModel('gemini-1.5-flash')
        
        logger.info("âœ… Content Generator initialisÃ©")
    
    def search_relevant_chunks(self, query: str, top_k: int = 15, 
                             filters: Dict[str, Any] = None) -> List[Dict[str, Any]]:
        """Rechercher les chunks pertinents pour une requÃªte - VERSION CORRIGÃ‰E"""
        
        try:
            # GÃ©nÃ©rer l'embedding de la requÃªte
            query_embedding = self.embedding_manager.get_embedding(query)
            
            # CORRECTION: VÃ©rifier que l'embedding est valide
            if not query_embedding or all(x == 0.0 for x in query_embedding):
                logger.error(f"Embedding invalide pour '{query}'")
                return []
            
            # Rechercher dans la base vectorielle avec plus de rÃ©sultats
            results = self.vector_manager.search_similar(
                query_embedding=query_embedding,
                top_k=top_k,
                filters=filters
            )
            
            logger.info(f"ğŸ” Recherche '{query}': {len(results)} chunks trouvÃ©s")
            
            # CORRECTION: VÃ©rifier le type des rÃ©sultats
            if not results:
                logger.warning(f"Aucun rÃ©sultat pour '{query}'")
                return []
            
            # Convertir en format utilisable
            relevant_chunks = []
            for result in results:
                try:
                    # CORRECTION: Gestion plus robuste des mÃ©tadonnÃ©es
                    metadata = result.metadata if hasattr(result, 'metadata') and result.metadata else {}
                    
                    chunk_data = {
                        "content": result.content if hasattr(result, 'content') else str(result),
                        "score": float(result.score) if hasattr(result, 'score') else 0.0,
                        "source": metadata.get("source_file", "Unknown"),
                        "section": metadata.get("section_title", "Unknown"),
                        "themes": metadata.get("themes", []),
                        "business_context": metadata.get("business_context", ""),
                        "confidence": metadata.get("confidence_score", 0.0)
                    }
                    
                    # Filtrer les chunks vides
                    if chunk_data["content"] and len(chunk_data["content"].strip()) > 20:
                        relevant_chunks.append(chunk_data)
                        
                except Exception as e:
                    logger.warning(f"Erreur traitement rÃ©sultat: {e}")
                    continue
            
            # Debug: afficher les meilleurs rÃ©sultats
            logger.info(f"ğŸ“Š Top 3 rÃ©sultats pour '{query}':")
            for i, chunk in enumerate(relevant_chunks[:3], 1):
                source_name = os.path.basename(chunk['source']) if chunk['source'] != "Unknown" else "Unknown"
                logger.info(f"  {i}. Score: {chunk['score']:.3f} - Source: {source_name}")
                logger.info(f"     Contenu: {chunk['content'][:100]}...")
            
            return relevant_chunks
            
        except Exception as e:
            logger.error(f"âŒ Erreur recherche '{query}': {e}")
            import traceback
            traceback.print_exc()
            return []
    
    def generate_section_content(self, section_title: str, search_queries: List[str],
                               max_chunks: int = 8) -> GeneratedSection:
        """GÃ©nÃ©rer le contenu d'une section spÃ©cifique"""
        
        logger.info(f"ğŸ“ GÃ©nÃ©ration de la section: {section_title}")
        
        # Collecter les chunks pertinents pour toutes les requÃªtes
        all_chunks = []
        for query in search_queries:
            chunks = self.search_relevant_chunks(query, top_k=max_chunks//len(search_queries) + 2)
            all_chunks.extend(chunks)
        
        # DÃ©duplication par source et score
        seen_content = set()
        unique_chunks = []
        for chunk in all_chunks:
            content_hash = hash(chunk["content"][:100])  # Hash des 100 premiers chars
            if content_hash not in seen_content:
                unique_chunks.append(chunk)
                seen_content.add(content_hash)
        
        # Trier par score de pertinence
        unique_chunks.sort(key=lambda x: x["score"], reverse=True)
        
        # Prendre les meilleurs chunks
        best_chunks = unique_chunks[:max_chunks]
        
        if not best_chunks:
            logger.warning(f"âŒ Aucun chunk trouvÃ© pour {section_title}")
            return GeneratedSection(
                title=section_title,
                content="Aucune information disponible dans les documents fournis.",
                confidence_score=0.0,
                sources_used=[],
                chunk_count=0
            )
        
        # Construire le prompt de gÃ©nÃ©ration - STYLE PROFESSIONNEL DIRECT
        context_text = self._build_context_from_chunks(best_chunks)
        
        prompt = f"""
        Vous Ãªtes un analyste financier senior rÃ©digeant une note d'investissement pour un comitÃ© d'investissement.
        
        SECTION: {section_title}
        
        INFORMATIONS DISPONIBLES:
        {context_text}
        
        INSTRUCTIONS STRICTES:
        1. RÃ©digez un texte professionnel DIRECT sans jamais mentionner les sources ("le document indique", "selon le rapport", etc.)
        2. PrÃ©sentez les faits comme des affirmations directes et factuelles
        3. Style: Note d'investissement institutionnelle (comme Goldman Sachs ou McKinsey)
        4. Longueur: 400-800 mots, dense et informatif
        5. Structure avec des sous-titres si pertinent
        6. Chiffres prÃ©cis et donnÃ©es factuelles en prioritÃ©
        7. Ã‰vitez les formulations vagues ou conditionnelles
        
        EXEMPLE DE STYLE:
        âŒ "Le document mentionne que l'entreprise rÃ©alise..."
        âœ… "L'entreprise rÃ©alise un chiffre d'affaires de Xâ‚¬..."
        
        âŒ "Selon les informations disponibles..."
        âœ… "L'activitÃ© principale porte sur..."
        
        RÃ‰DIGEZ LA SECTION:
        """
        
        try:
            # GÃ©nÃ©rer le contenu
            response = self.generation_model.generate_content(
                prompt,
                generation_config=genai.types.GenerationConfig(
                    temperature=0.3,
                    max_output_tokens=1500,
                    top_p=0.8
                )
            )
            
            generated_content = response.text.strip()
            
            # Calculer le score de confiance
            avg_score = sum(chunk["score"] for chunk in best_chunks) / len(best_chunks)
            confidence_score = min(avg_score * 1.2, 1.0)  # Boost lÃ©ger
            
            # Sources utilisÃ©es
            sources_used = list(set(chunk["source"] for chunk in best_chunks))
            
            logger.info(f"âœ… Section '{section_title}' gÃ©nÃ©rÃ©e: {len(generated_content)} chars")
            
            return GeneratedSection(
                title=section_title,
                content=generated_content,
                confidence_score=confidence_score,
                sources_used=sources_used,
                chunk_count=len(best_chunks)
            )
            
        except Exception as e:
            logger.error(f"âŒ Erreur gÃ©nÃ©ration section {section_title}: {e}")
            return GeneratedSection(
                title=section_title,
                content=f"Erreur lors de la gÃ©nÃ©ration: {str(e)}",
                confidence_score=0.0,
                sources_used=[],
                chunk_count=0
            )
    
    def _build_context_from_chunks(self, chunks: List[Dict[str, Any]]) -> str:
        """Construire le contexte Ã  partir des chunks"""
        context_parts = []
        
        for i, chunk in enumerate(chunks, 1):
            source_name = os.path.basename(chunk["source"]).replace(".pdf", "")
            
            context_part = f"""
            === DOCUMENT {i}: {source_name} ===
            Section: {chunk["section"]}
            ThÃ¨mes: {', '.join(chunk["themes"])}
            Score: {chunk["score"]:.3f}
            
            Contenu:
            {chunk["content"]}
            
            """
            context_parts.append(context_part)
        
        return "\n".join(context_parts)
    
    def generate_company_presentation_only(self) -> GeneratedSection:
        """GÃ©nÃ©rer UNIQUEMENT une prÃ©sentation d'entreprise complÃ¨te - VERSION HYBRIDE"""
        
        logger.info("ğŸ¢ GÃ©nÃ©ration de la prÃ©sentation d'entreprise avec recherche hybride")
        
        # STRATÃ‰GIE 1: Recherche ciblÃ©e par sections
        section_queries = [
            "PrÃ©sentation de l'Entreprise",
            "ModÃ¨le d'affaires", 
            "business model",
            "activitÃ© principale"
        ]
        
        # STRATÃ‰GIE 2: Recherche par noms d'entreprise identifiÃ©s
        company_queries = [
            "R-Group", "R Group", "RGroup",
            "InnoTech", "InnoTech Solutions",
            "Dynamia Invest", 
            "Reno Energy", "Reno",
            "Pony Energy"
        ]
        
        # STRATÃ‰GIE 3: Recherche par contexte business
        business_queries = [
            "entreprise sociÃ©tÃ©",
            "activitÃ© mÃ©tier",
            "secteur d'activitÃ©",
            "organisation structure"
        ]
        
        # STRATÃ‰GIE 4: Recherche par thÃ¨mes identifiÃ©s
        theme_queries = [
            "Solutions logicielles",
            "Ã‰nergie renouvelable", 
            "RÃ©novation Ã©nergÃ©tique",
            "Transition Ã©nergÃ©tique"
        ]
        
        all_queries = section_queries + company_queries + business_queries + theme_queries
        
        # Collecter TOUS les chunks avec scores
        all_chunks_with_score = []
        
        for query in all_queries:
            try:
                chunks = self.search_relevant_chunks(query, top_k=15)
                for chunk in chunks:
                    if chunk["score"] > 0.5:  # Seuil de pertinence
                        chunk_enhanced = chunk.copy()
                        chunk_enhanced["search_query"] = query
                        all_chunks_with_score.append(chunk_enhanced)
            except Exception as e:
                logger.warning(f"Erreur recherche '{query}': {e}")
                continue
        
        logger.info(f"ğŸ“Š Total chunks collectÃ©s: {len(all_chunks_with_score)}")
        
        # DÃ‰DUPLICATION INTELLIGENTE - moins agressive
        unique_chunks = []
        seen_sources_content = {}
        
        # Grouper par source et garder les meilleurs par source
        for chunk in all_chunks_with_score:
            source = chunk["source"]
            content_start = chunk["content"][:50]  # Plus court pour moins filtrer
            
            key = f"{source}_{content_start}"
            
            if key not in seen_sources_content:
                seen_sources_content[key] = chunk
            else:
                # Garder le chunk avec le meilleur score
                if chunk["score"] > seen_sources_content[key]["score"]:
                    seen_sources_content[key] = chunk
        
        unique_chunks = list(seen_sources_content.values())
        
        # Trier par score ET privilÃ©gier certaines sections
        def chunk_priority(chunk):
            score = chunk["score"]
            
            # Bonus pour les sections importantes
            section = chunk.get("section", "").lower()
            if "prÃ©sentation" in section and "entreprise" in section:
                score += 0.2
            elif "modÃ¨le" in section or "business" in section:
                score += 0.15
            elif "activitÃ©" in section:
                score += 0.1
            
            # Bonus pour les entreprises principales
            content = chunk["content"].lower()
            if "r-group" in content or "innotech" in content:
                score += 0.1
            
            return score
        
        unique_chunks.sort(key=chunk_priority, reverse=True)
        
        # Prendre plus de chunks pour avoir plus de contexte
        best_chunks = unique_chunks[:15]  
        
        logger.info(f"ğŸ“Š AprÃ¨s dÃ©duplication: {len(unique_chunks)} chunks uniques, {len(best_chunks)} sÃ©lectionnÃ©s")
        
        if not best_chunks:
            logger.warning(f"âŒ Aucun chunk trouvÃ© pour la prÃ©sentation")
            return GeneratedSection(
                title="PrÃ©sentation de l'Entreprise",
                content="Aucune information dÃ©taillÃ©e disponible dans les documents fournis.",
                confidence_score=0.0,
                sources_used=[],
                chunk_count=0
            )
        
        # Log des chunks sÃ©lectionnÃ©s pour debug
        logger.info(f"ğŸ¯ Chunks sÃ©lectionnÃ©s:")
        for i, chunk in enumerate(best_chunks[:5], 1):
            source_name = os.path.basename(chunk["source"])
            logger.info(f"  {i}. Score: {chunk['score']:.3f} - {source_name}")
            logger.info(f"     Section: {chunk.get('section', 'Unknown')}")
            logger.info(f"     RequÃªte: {chunk.get('search_query', 'N/A')}")
            logger.info(f"     Contenu: {chunk['content'][:100]}...")
        
        # Construire le contexte enrichi
        context_text = self._build_company_context(best_chunks)
        
        prompt = f"""
        Vous Ãªtes un analyste financier senior rÃ©digeant la section "PrÃ©sentation de l'Entreprise" d'une note d'investissement institutionnelle.
        
        Vous avez collectÃ© des informations sur plusieurs entreprises du secteur de l'Ã©nergie et de la technologie.
        
        INFORMATIONS COLLECTÃ‰ES:
        {context_text}
        
        INSTRUCTIONS:
        1. Identifiez les ENTREPRISES PRINCIPALES mentionnÃ©es (R-Group, InnoTech, Dynamia Invest, etc.)
        2. RÃ©digez une prÃ©sentation structurÃ©e couvrant:
           - Vue d'ensemble des activitÃ©s
           - Structure du groupe/des entreprises
           - Secteurs d'intervention
           - ModÃ¨les Ã©conomiques
           - Positionnement concurrentiel
        
        3. Style: Note d'investissement professionnelle
        4. Ton: Factuel, sans mentionner les sources
        5. Longueur: 600-1000 mots
        6. Structurez avec des sous-titres
        
        RÃ‰DIGEZ LA PRÃ‰SENTATION DES ENTREPRISES:
        """
        
        try:
            response = self.generation_model.generate_content(
                prompt,
                generation_config=genai.types.GenerationConfig(
                    temperature=0.2,
                    max_output_tokens=2500,
                    top_p=0.9
                )
            )
            
            generated_content = response.text.strip()
            
            # Score de confiance basÃ© sur la qualitÃ© des chunks
            weighted_score = sum(chunk["score"] * chunk.get("confidence", 0.5) for chunk in best_chunks)
            avg_score = weighted_score / len(best_chunks) if best_chunks else 0
            confidence_score = min(avg_score * 1.1, 1.0)
            
            sources_used = list(set(chunk["source"] for chunk in best_chunks))
            
            logger.info(f"âœ… PrÃ©sentation gÃ©nÃ©rÃ©e: {len(generated_content)} chars, confiance {confidence_score:.2f}")
            
            return GeneratedSection(
                title="PrÃ©sentation de l'Entreprise",
                content=generated_content,
                confidence_score=confidence_score,
                sources_used=sources_used,
                chunk_count=len(best_chunks)
            )
            
        except Exception as e:
            logger.error(f"âŒ Erreur gÃ©nÃ©ration prÃ©sentation: {e}")
            return GeneratedSection(
                title="PrÃ©sentation de l'Entreprise",
                content=f"Erreur lors de la gÃ©nÃ©ration: {str(e)}",
                confidence_score=0.0,
                sources_used=[],
                chunk_count=0
            )
    
    def _build_company_context(self, chunks: List[Dict[str, Any]]) -> str:
        """Construire un contexte spÃ©cialisÃ© pour prÃ©sentation d'entreprise"""
        context_parts = []
        
        # Grouper par source pour une meilleure organisation
        sources_chunks = {}
        for chunk in chunks:
            source = chunk["source"]
            if source not in sources_chunks:
                sources_chunks[source] = []
            sources_chunks[source].append(chunk)
        
        for source, source_chunks in sources_chunks.items():
            source_name = os.path.basename(source).replace(".pdf", "")
            context_parts.append(f"\n=== DOCUMENT: {source_name} ===")
            
            for chunk in source_chunks:
                section = chunk.get("section", "Section inconnue")
                themes = ", ".join(chunk.get("themes", []))
                
                context_part = f"""
SECTION: {section}
THÃˆMES: {themes}
SCORE: {chunk["score"]:.3f}

{chunk["content"]}
"""
                context_parts.append(context_part)
        
        return "\n".join(context_parts)
    
    def _build_rich_context_from_chunks(self, chunks: List[Dict[str, Any]]) -> str:
        """Construire un contexte riche Ã  partir des chunks"""
        context_parts = []
        
        for i, chunk in enumerate(chunks, 1):
            source_name = os.path.basename(chunk["source"]).replace(".pdf", "")
            
            context_part = f"""
            INFORMATION {i} [Score: {chunk["score"]:.3f}]:
            {chunk["content"]}
            """
            context_parts.append(context_part)
        
        return "\n".join(context_parts)
    
    def export_to_text(self, sections: Dict[str, GeneratedSection], 
                      output_path: str = "data/output/presentation_entreprise.txt") -> str:
        """Exporter la prÃ©sentation en fichier texte"""
        
        # CrÃ©er le dossier de sortie
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        
        # Construire le contenu complet
        content_lines = []
        
        # En-tÃªte
        content_lines.extend([
            "=" * 80,
            "PRÃ‰SENTATION D'ENTREPRISE",
            "GÃ©nÃ©rÃ© automatiquement par EODEN POC",
            f"Date: {self._get_current_date()}",
            "=" * 80,
            ""
        ])
        
        # Statistiques globales
        total_sources = set()
        total_chunks = 0
        avg_confidence = 0
        
        for section in sections.values():
            total_sources.update(section.sources_used)
            total_chunks += section.chunk_count
            avg_confidence += section.confidence_score
        
        avg_confidence = avg_confidence / len(sections) if sections else 0
        
        content_lines.extend([
            "ğŸ“Š STATISTIQUES DE GÃ‰NÃ‰RATION",
            f"â€¢ Sections gÃ©nÃ©rÃ©es: {len(sections)}",
            f"â€¢ Documents sources: {len(total_sources)}",
            f"â€¢ Chunks utilisÃ©s: {total_chunks}",
            f"â€¢ Confiance moyenne: {avg_confidence:.2f}/1.0",
            "",
            "ğŸ“ SOURCES UTILISÃ‰ES:",
        ])
        
        for i, source in enumerate(sorted(total_sources), 1):
            source_name = os.path.basename(source)
            content_lines.append(f"  {i}. {source_name}")
        
        content_lines.extend(["", "=" * 80, ""])
        
        # Sections gÃ©nÃ©rÃ©es
        for section_title, section in sections.items():
            content_lines.extend([
                f"## {section_title.upper()}",
                f"Confiance: {section.confidence_score:.2f}/1.0 | Chunks: {section.chunk_count} | Sources: {len(section.sources_used)}",
                "-" * 60,
                "",
                section.content,
                "",
                "=" * 80,
                ""
            ])
        
        # Pied de page
        content_lines.extend([
            "NOTES:",
            "â€¢ Cette prÃ©sentation a Ã©tÃ© gÃ©nÃ©rÃ©e automatiquement Ã  partir des documents fournis",
            "â€¢ Les scores de confiance indiquent la pertinence des informations trouvÃ©es",
            "â€¢ Une relecture et validation manuelle est recommandÃ©e",
            ""
        ])
        
        # Ã‰crire le fichier
        full_content = "\n".join(content_lines)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(full_content)
        
        logger.info(f"âœ… PrÃ©sentation exportÃ©e: {output_path}")
        return output_path
    
    def _get_current_date(self) -> str:
        """Obtenir la date actuelle formatÃ©e"""
        import datetime
        return datetime.datetime.now().strftime("%d/%m/%Y %H:%M")

# Fonction principale pour tester
def main():
    """Fonction principale de test"""
    print("ğŸš€ Test du gÃ©nÃ©rateur de contenu")
    
    try:
        # CrÃ©er le gÃ©nÃ©rateur
        generator = ContentGenerator()
        
        # GÃ©nÃ©rer la prÃ©sentation
        print("ğŸ“ GÃ©nÃ©ration de la prÃ©sentation d'entreprise...")
        sections = generator.generate_company_presentation()
        
        # Exporter en fichier texte
        output_path = generator.export_to_text(sections)
        
        print(f"âœ… PrÃ©sentation gÃ©nÃ©rÃ©e et sauvegardÃ©e: {output_path}")
        
        # Afficher un rÃ©sumÃ©
        print(f"\nğŸ“Š RÃ©sumÃ©:")
        for title, section in sections.items():
            print(f"  â€¢ {title}: {len(section.content)} chars, confiance {section.confidence_score:.2f}")
        
        print(f"\nğŸ“– Ouvrir le fichier pour voir le rÃ©sultat complet !")
        
    except Exception as e:
        print(f"âŒ Erreur: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()