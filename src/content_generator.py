"""
G√©n√©rateur de contenu pour les notes d'investissement
Utilise la base vectorielle pour cr√©er du contenu intelligent
"""

import os
import logging
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
import google.generativeai as genai
from dotenv import load_dotenv

# Imports locaux
from vector_store import VectorManager
from embedding_manager import EmbeddingManager

logger = logging.getLogger(__name__)

@dataclass
class GeneratedSection:
    """Section g√©n√©r√©e avec m√©tadonn√©es"""
    title: str
    content: str
    confidence_score: float
    sources_used: List[str]
    chunk_count: int

class ContentGenerator:
    """G√©n√©rateur de contenu intelligent"""
    
    def __init__(self, config_path: str = "config/settings.yaml"):
        load_dotenv()
        
        # Initialiser les composants
        self.embedding_manager = EmbeddingManager(
            api_key=os.getenv("GEMINI_API_KEY")
        )
        self.vector_manager = VectorManager(config_path)
        
        # Mod√®le de g√©n√©ration
        genai.configure(api_key=os.getenv("GEMINI_API_KEY"))
        self.generation_model = genai.GenerativeModel('gemini-1.5-flash')
        
        logger.info("‚úÖ Content Generator initialis√©")
    
    def search_relevant_chunks(self, query: str, top_k: int = 15, 
                             filters: Dict[str, Any] = None) -> List[Dict[str, Any]]:
        """Rechercher les chunks pertinents pour une requ√™te - VERSION CORRIG√âE"""
        
        try:
            # G√©n√©rer l'embedding de la requ√™te
            query_embedding = self.embedding_manager.get_embedding(query)
            
            # CORRECTION: V√©rifier que l'embedding est valide
            if not query_embedding or all(x == 0.0 for x in query_embedding):
                logger.error(f"Embedding invalide pour '{query}'")
                return []
            
            # Rechercher dans la base vectorielle avec plus de r√©sultats
            results = self.vector_manager.search_similar(
                query_embedding=query_embedding,
                top_k=top_k,
                filters=filters
            )
            
            logger.info(f"üîç Recherche '{query}': {len(results)} chunks trouv√©s")
            
            # CORRECTION: V√©rifier le type des r√©sultats
            if not results:
                logger.warning(f"Aucun r√©sultat pour '{query}'")
                return []
            
            # Convertir en format utilisable
            relevant_chunks = []
            for result in results:
                try:
                    # CORRECTION: Gestion plus robuste des m√©tadonn√©es
                    metadata = result.metadata if hasattr(result, 'metadata') and result.metadata else {}
                    
                    chunk_data = {
                        "content": result.content if hasattr(result, 'content') else str(result),
                        "score": float(result.score) if hasattr(result, 'score') else 0.0,
                        "source": metadata.get("source_file", "Unknown"),
                        "section": metadata.get("section_title", "Unknown"),
                        "themes": metadata.get("themes", []),
                        "business_context": metadata.get("business_context", ""),
                        "confidence": metadata.get("confidence_score", 0.0)
                    }
                    
                    # Filtrer les chunks vides
                    if chunk_data["content"] and len(chunk_data["content"].strip()) > 20:
                        relevant_chunks.append(chunk_data)
                        
                except Exception as e:
                    logger.warning(f"Erreur traitement r√©sultat: {e}")
                    continue
            
            # Debug: afficher les meilleurs r√©sultats
            logger.info(f"üìä Top 3 r√©sultats pour '{query}':")
            for i, chunk in enumerate(relevant_chunks[:3], 1):
                source_name = os.path.basename(chunk['source']) if chunk['source'] != "Unknown" else "Unknown"
                logger.info(f"  {i}. Score: {chunk['score']:.3f} - Source: {source_name}")
                logger.info(f"     Contenu: {chunk['content'][:100]}...")
            
            return relevant_chunks
            
        except Exception as e:
            logger.error(f"‚ùå Erreur recherche '{query}': {e}")
            import traceback
            traceback.print_exc()
            return []
    
    def generate_section_content(self, section_title: str, search_queries: List[str],
                               max_chunks: int = 8) -> GeneratedSection:
        """G√©n√©rer le contenu d'une section sp√©cifique"""
        
        logger.info(f"üìù G√©n√©ration de la section: {section_title}")
        
        # Collecter les chunks pertinents pour toutes les requ√™tes
        all_chunks = []
        for query in search_queries:
            chunks = self.search_relevant_chunks(query, top_k=max_chunks//len(search_queries) + 2)
            all_chunks.extend(chunks)
        
        # D√©duplication par source et score
        seen_content = set()
        unique_chunks = []
        for chunk in all_chunks:
            content_hash = hash(chunk["content"][:100])  # Hash des 100 premiers chars
            if content_hash not in seen_content:
                unique_chunks.append(chunk)
                seen_content.add(content_hash)
        
        # Trier par score de pertinence
        unique_chunks.sort(key=lambda x: x["score"], reverse=True)
        
        # Prendre les meilleurs chunks
        best_chunks = unique_chunks[:max_chunks]
        
        if not best_chunks:
            logger.warning(f"‚ùå Aucun chunk trouv√© pour {section_title}")
            return GeneratedSection(
                title=section_title,
                content="Aucune information disponible dans les documents fournis.",
                confidence_score=0.0,
                sources_used=[],
                chunk_count=0
            )
        
        # Construire le prompt de g√©n√©ration - STYLE PROFESSIONNEL DIRECT
        context_text = self._build_context_from_chunks(best_chunks)
        
        prompt = f"""
        Vous √™tes un analyste financier senior r√©digeant une note d'investissement pour un comit√© d'investissement.
        
        SECTION: {section_title}
        
        INFORMATIONS DISPONIBLES:
        {context_text}
        
        INSTRUCTIONS STRICTES:
        1. R√©digez un texte professionnel DIRECT sans jamais mentionner les sources ("le document indique", "selon le rapport", etc.)
        2. Pr√©sentez les faits comme des affirmations directes et factuelles
        3. Style: Note d'investissement institutionnelle (comme Goldman Sachs ou McKinsey)
        4. Longueur: 400-800 mots, dense et informatif
        5. Structure avec des sous-titres si pertinent
        6. Chiffres pr√©cis et donn√©es factuelles en priorit√©
        7. √âvitez les formulations vagues ou conditionnelles
        
        EXEMPLE DE STYLE:
        ‚ùå "Le document mentionne que l'entreprise r√©alise..."
        ‚úÖ "L'entreprise r√©alise un chiffre d'affaires de X‚Ç¨..."
        
        ‚ùå "Selon les informations disponibles..."
        ‚úÖ "L'activit√© principale porte sur..."
        
        R√âDIGEZ LA SECTION:
        """
        
        try:
            # G√©n√©rer le contenu
            response = self.generation_model.generate_content(
                prompt,
                generation_config=genai.types.GenerationConfig(
                    temperature=0.3,
                    max_output_tokens=1500,
                    top_p=0.8
                )
            )
            
            generated_content = response.text.strip()
            
            # Calculer le score de confiance
            avg_score = sum(chunk["score"] for chunk in best_chunks) / len(best_chunks)
            confidence_score = min(avg_score * 1.2, 1.0)  # Boost l√©ger
            
            # Sources utilis√©es
            sources_used = list(set(chunk["source"] for chunk in best_chunks))
            
            logger.info(f"‚úÖ Section '{section_title}' g√©n√©r√©e: {len(generated_content)} chars")
            
            return GeneratedSection(
                title=section_title,
                content=generated_content,
                confidence_score=confidence_score,
                sources_used=sources_used,
                chunk_count=len(best_chunks)
            )
            
        except Exception as e:
            logger.error(f"‚ùå Erreur g√©n√©ration section {section_title}: {e}")
            return GeneratedSection(
                title=section_title,
                content=f"Erreur lors de la g√©n√©ration: {str(e)}",
                confidence_score=0.0,
                sources_used=[],
                chunk_count=0
            )
    
    def _build_context_from_chunks(self, chunks: List[Dict[str, Any]]) -> str:
        """Construire le contexte √† partir des chunks"""
        context_parts = []
        
        for i, chunk in enumerate(chunks, 1):
            source_name = os.path.basename(chunk["source"]).replace(".pdf", "")
            
            context_part = f"""
            === DOCUMENT {i}: {source_name} ===
            Section: {chunk["section"]}
            Th√®mes: {', '.join(chunk["themes"])}
            Score: {chunk["score"]:.3f}
            
            Contenu:
            {chunk["content"]}
            
            """
            context_parts.append(context_part)
        
        return "\n".join(context_parts)
    
    def generate_company_presentation_only(self) -> GeneratedSection:
        """G√©n√©rer UNIQUEMENT une pr√©sentation d'entreprise compl√®te - VERSION HYBRIDE"""
        
        logger.info("üè¢ G√©n√©ration de la pr√©sentation d'entreprise avec recherche hybride")
        
        # STRAT√âGIE 1: Recherche cibl√©e par sections
        section_queries = [
            "Pr√©sentation de l'Entreprise",
            "Mod√®le d'affaires", 
            "business model",
            "activit√© principale"
        ]
        
        # STRAT√âGIE 2: Recherche par noms d'entreprise identifi√©s
        company_queries = [
            "R-Group", "R Group", "RGroup",
            "InnoTech", "InnoTech Solutions",
            "Dynamia Invest", 
            "Reno Energy", "Reno",
            "Pony Energy"
        ]
        
        # STRAT√âGIE 3: Recherche par contexte business
        business_queries = [
            "entreprise soci√©t√©",
            "activit√© m√©tier",
            "secteur d'activit√©",
            "organisation structure"
        ]
        
        # STRAT√âGIE 4: Recherche par th√®mes identifi√©s
        theme_queries = [
            "Solutions logicielles",
            "√ânergie renouvelable", 
            "R√©novation √©nerg√©tique",
            "Transition √©nerg√©tique"
        ]
        
        all_queries = section_queries + company_queries + business_queries + theme_queries
        
        # Collecter TOUS les chunks avec scores
        all_chunks_with_score = []
        
        for query in all_queries:
            try:
                chunks = self.search_relevant_chunks(query, top_k=15)
                for chunk in chunks:
                    if chunk["score"] > 0.5:  # Seuil de pertinence
                        chunk_enhanced = chunk.copy()
                        chunk_enhanced["search_query"] = query
                        all_chunks_with_score.append(chunk_enhanced)
            except Exception as e:
                logger.warning(f"Erreur recherche '{query}': {e}")
                continue
        
        logger.info(f"üìä Total chunks collect√©s: {len(all_chunks_with_score)}")
        
        # D√âDUPLICATION INTELLIGENTE - moins agressive
        unique_chunks = []
        seen_sources_content = {}
        
        # Grouper par source et garder les meilleurs par source
        for chunk in all_chunks_with_score:
            source = chunk["source"]
            content_start = chunk["content"][:50]  # Plus court pour moins filtrer
            
            key = f"{source}_{content_start}"
            
            if key not in seen_sources_content:
                seen_sources_content[key] = chunk
            else:
                # Garder le chunk avec le meilleur score
                if chunk["score"] > seen_sources_content[key]["score"]:
                    seen_sources_content[key] = chunk
        
        unique_chunks = list(seen_sources_content.values())
        
        # Trier par score ET privil√©gier certaines sections
        def chunk_priority(chunk):
            score = chunk["score"]
            
            # Bonus pour les sections importantes
            section = chunk.get("section", "").lower()
            if "pr√©sentation" in section and "entreprise" in section:
                score += 0.2
            elif "mod√®le" in section or "business" in section:
                score += 0.15
            elif "activit√©" in section:
                score += 0.1
            
            # Bonus pour les entreprises principales
            content = chunk["content"].lower()
            if "r-group" in content or "innotech" in content:
                score += 0.1
            
            return score
        
        unique_chunks.sort(key=chunk_priority, reverse=True)
        
        # Prendre plus de chunks pour avoir plus de contexte
        best_chunks = unique_chunks[:15]  
        
        logger.info(f"üìä Apr√®s d√©duplication: {len(unique_chunks)} chunks uniques, {len(best_chunks)} s√©lectionn√©s")
        
        if not best_chunks:
            logger.warning(f"‚ùå Aucun chunk trouv√© pour la pr√©sentation")
            return GeneratedSection(
                title="Pr√©sentation de l'Entreprise",
                content="Aucune information d√©taill√©e disponible dans les documents fournis.",
                confidence_score=0.0,
                sources_used=[],
                chunk_count=0
            )
        
        # Log des chunks s√©lectionn√©s pour debug
        logger.info(f"üéØ Chunks s√©lectionn√©s:")
        for i, chunk in enumerate(best_chunks[:5], 1):
            source_name = os.path.basename(chunk["source"])
            logger.info(f"  {i}. Score: {chunk['score']:.3f} - {source_name}")
            logger.info(f"     Section: {chunk.get('section', 'Unknown')}")
            logger.info(f"     Requ√™te: {chunk.get('search_query', 'N/A')}")
            logger.info(f"     Contenu: {chunk['content'][:100]}...")
        
        # Construire le contexte enrichi
        context_text = self._build_company_context(best_chunks)
        
        prompt = f"""
        Vous √™tes un analyste financier senior r√©digeant la section "Pr√©sentation de l'Entreprise" d'une note d'investissement institutionnelle.
        
        Vous avez collect√© des informations sur plusieurs entreprises du secteur de l'√©nergie et de la technologie.
        
        INFORMATIONS COLLECT√âES:
        {context_text}
        
        INSTRUCTIONS:
        1. Identifiez les ENTREPRISES PRINCIPALES mentionn√©es (R-Group, InnoTech, Dynamia Invest, etc.)
        2. R√©digez une pr√©sentation structur√©e couvrant:
           - Vue d'ensemble des activit√©s
           - Structure du groupe/des entreprises
           - Secteurs d'intervention
           - Mod√®les √©conomiques
           - Positionnement concurrentiel
        
        3. Style: Note d'investissement professionnelle
        4. Ton: Factuel, sans mentionner les sources
        5. Longueur: 600-1000 mots
        6. Structurez avec des sous-titres
        
        R√âDIGEZ LA PR√âSENTATION DES ENTREPRISES:
        """
        
        try:
            response = self.generation_model.generate_content(
                prompt,
                generation_config=genai.types.GenerationConfig(
                    temperature=0.2,
                    max_output_tokens=2500,
                    top_p=0.9
                )
            )
            
            generated_content = response.text.strip()
            
            # Score de confiance bas√© sur la qualit√© des chunks
            weighted_score = sum(chunk["score"] * chunk.get("confidence", 0.5) for chunk in best_chunks)
            avg_score = weighted_score / len(best_chunks) if best_chunks else 0
            confidence_score = min(avg_score * 1.1, 1.0)
            
            sources_used = list(set(chunk["source"] for chunk in best_chunks))
            
            logger.info(f"‚úÖ Pr√©sentation g√©n√©r√©e: {len(generated_content)} chars, confiance {confidence_score:.2f}")
            
            return GeneratedSection(
                title="Pr√©sentation de l'Entreprise",
                content=generated_content,
                confidence_score=confidence_score,
                sources_used=sources_used,
                chunk_count=len(best_chunks)
            )
            
        except Exception as e:
            logger.error(f"‚ùå Erreur g√©n√©ration pr√©sentation: {e}")
            return GeneratedSection(
                title="Pr√©sentation de l'Entreprise",
                content=f"Erreur lors de la g√©n√©ration: {str(e)}",
                confidence_score=0.0,
                sources_used=[],
                chunk_count=0
            )
    
    def _build_company_context(self, chunks: List[Dict[str, Any]]) -> str:
        """Construire un contexte sp√©cialis√© pour pr√©sentation d'entreprise"""
        context_parts = []
        
        # Grouper par source pour une meilleure organisation
        sources_chunks = {}
        for chunk in chunks:
            source = chunk["source"]
            if source not in sources_chunks:
                sources_chunks[source] = []
            sources_chunks[source].append(chunk)
        
        for source, source_chunks in sources_chunks.items():
            source_name = os.path.basename(source).replace(".pdf", "")
            context_parts.append(f"\n=== DOCUMENT: {source_name} ===")
            
            for chunk in source_chunks:
                section = chunk.get("section", "Section inconnue")
                themes = ", ".join(chunk.get("themes", []))
                
                context_part = f"""
SECTION: {section}
TH√àMES: {themes}
SCORE: {chunk["score"]:.3f}

{chunk["content"]}
"""
                context_parts.append(context_part)
        
        return "\n".join(context_parts)
    
    def _build_rich_context_from_chunks(self, chunks: List[Dict[str, Any]]) -> str:
        """Construire un contexte riche √† partir des chunks"""
        context_parts = []
        
        for i, chunk in enumerate(chunks, 1):
            source_name = os.path.basename(chunk["source"]).replace(".pdf", "")
            
            context_part = f"""
            INFORMATION {i} [Score: {chunk["score"]:.3f}]:
            {chunk["content"]}
            """
            context_parts.append(context_part)
        
        return "\n".join(context_parts)
    
    def export_to_text(self, sections: Dict[str, GeneratedSection], 
                      output_path: str = "data/output/presentation_entreprise.txt") -> str:
        """Exporter la pr√©sentation en fichier texte"""
        
        # Cr√©er le dossier de sortie
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        
        # Construire le contenu complet
        content_lines = []
        
        # En-t√™te
        content_lines.extend([
            "=" * 80,
            "PR√âSENTATION D'ENTREPRISE",
            "G√©n√©r√© automatiquement par EODEN POC",
            f"Date: {self._get_current_date()}",
            "=" * 80,
            ""
        ])
        
        # Statistiques globales
        total_sources = set()
        total_chunks = 0
        avg_confidence = 0
        
        for section in sections.values():
            total_sources.update(section.sources_used)
            total_chunks += section.chunk_count
            avg_confidence += section.confidence_score
        
        avg_confidence = avg_confidence / len(sections) if sections else 0
        
        content_lines.extend([
            "üìä STATISTIQUES DE G√âN√âRATION",
            f"‚Ä¢ Sections g√©n√©r√©es: {len(sections)}",
            f"‚Ä¢ Documents sources: {len(total_sources)}",
            f"‚Ä¢ Chunks utilis√©s: {total_chunks}",
            f"‚Ä¢ Confiance moyenne: {avg_confidence:.2f}/1.0",
            "",
            "üìÅ SOURCES UTILIS√âES:",
        ])
        
        for i, source in enumerate(sorted(total_sources), 1):
            source_name = os.path.basename(source)
            content_lines.append(f"  {i}. {source_name}")
        
        content_lines.extend(["", "=" * 80, ""])
        
        # Sections g√©n√©r√©es
        for section_title, section in sections.items():
            content_lines.extend([
                f"## {section_title.upper()}",
                f"Confiance: {section.confidence_score:.2f}/1.0 | Chunks: {section.chunk_count} | Sources: {len(section.sources_used)}",
                "-" * 60,
                "",
                section.content,
                "",
                "=" * 80,
                ""
            ])
        
        # Pied de page
        content_lines.extend([
            "NOTES:",
            "‚Ä¢ Cette pr√©sentation a √©t√© g√©n√©r√©e automatiquement √† partir des documents fournis",
            "‚Ä¢ Les scores de confiance indiquent la pertinence des informations trouv√©es",
            "‚Ä¢ Une relecture et validation manuelle est recommand√©e",
            ""
        ])
        
        # √âcrire le fichier
        full_content = "\n".join(content_lines)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(full_content)
        
        logger.info(f"‚úÖ Pr√©sentation export√©e: {output_path}")
        return output_path
    
    def _get_current_date(self) -> str:
        """Obtenir la date actuelle format√©e"""
        import datetime
        return datetime.datetime.now().strftime("%d/%m/%Y %H:%M")

# Fonction principale pour tester
def main():
    """Fonction principale de test"""
    print("üöÄ Test du g√©n√©rateur de contenu")
    
    try:
        # Cr√©er le g√©n√©rateur
        generator = ContentGenerator()
        
        # G√©n√©rer la pr√©sentation
        print("üìù G√©n√©ration de la pr√©sentation d'entreprise...")
        sections = generator.generate_company_presentation()
        
        # Exporter en fichier texte
        output_path = generator.export_to_text(sections)
        
        print(f"‚úÖ Pr√©sentation g√©n√©r√©e et sauvegard√©e: {output_path}")
        
        # Afficher un r√©sum√©
        print(f"\nüìä R√©sum√©:")
        for title, section in sections.items():
            print(f"  ‚Ä¢ {title}: {len(section.content)} chars, confiance {section.confidence_score:.2f}")
        
        print(f"\nüìñ Ouvrir le fichier pour voir le r√©sultat complet !")
        
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()